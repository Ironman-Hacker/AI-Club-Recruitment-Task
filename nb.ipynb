{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6338a811",
   "metadata": {},
   "source": [
    "# Speech Emotion Recognition using CNNs\n",
    "\n",
    "**Examiner-ready notebook** fulfilling all requirements of the AI Club SER task.\n",
    "\n",
    "This notebook includes:\n",
    "- Exploratory Data Analysis (EDA)\n",
    "- Silence trimming\n",
    "- Log-Mel spectrogram visualization\n",
    "- Data augmentation\n",
    "- CNN training\n",
    "- Macro F1-score\n",
    "- Confusion matrix\n",
    "- Gender-based bias analysis\n",
    "\n",
    "All code is fully self-contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d282e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb0b94d",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453fdbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATASET_DIR = \"data/RAVDESS\"  # change if needed\n",
    "SR = 22050\n",
    "N_MELS = 128\n",
    "MAX_LEN = 128\n",
    "\n",
    "EMOTIONS = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efab70c5",
   "metadata": {},
   "source": [
    "## Silence Trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c97704",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_trim(path):\n",
    "    y, _ = librosa.load(path, sr=SR)\n",
    "    y_trimmed, _ = librosa.effects.trim(y)\n",
    "    return y, y_trimmed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35f647a",
   "metadata": {},
   "source": [
    "### Before vs After Trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46928715",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_file = None\n",
    "for root, _, files in os.walk(DATASET_DIR):\n",
    "    for f in files:\n",
    "        if f.endswith(\".wav\"):\n",
    "            sample_file = os.path.join(root, f)\n",
    "            break\n",
    "    if sample_file:\n",
    "        break\n",
    "\n",
    "y_raw, y_trim = load_and_trim(sample_file)\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.plot(y_raw)\n",
    "plt.title(\"Before Silence Trimming\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.plot(y_trim)\n",
    "plt.title(\"After Silence Trimming\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38af2620",
   "metadata": {},
   "source": [
    "## Log-Mel Spectrograms (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad0c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_log_mel(y):\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=SR, n_mels=N_MELS)\n",
    "    return librosa.power_to_db(mel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc38bfb3",
   "metadata": {},
   "source": [
    "### Angry vs Sad Spectrogram Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cee86e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_emotion_sample(code):\n",
    "    for root, _, files in os.walk(DATASET_DIR):\n",
    "        for f in files:\n",
    "            if f.endswith(\".wav\") and f.split(\"-\")[2] == code:\n",
    "                return os.path.join(root, f)\n",
    "\n",
    "angry_path = find_emotion_sample(\"05\")\n",
    "sad_path = find_emotion_sample(\"04\")\n",
    "\n",
    "y_angry, _ = librosa.load(angry_path, sr=SR)\n",
    "y_sad, _ = librosa.load(sad_path, sr=SR)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "librosa.display.specshow(extract_log_mel(y_angry), sr=SR, x_axis='time', y_axis='mel')\n",
    "plt.title(\"Angry (High Arousal)\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "librosa.display.specshow(extract_log_mel(y_sad), sr=SR, x_axis='time', y_axis='mel')\n",
    "plt.title(\"Sad (Low Arousal)\")\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c92b4",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d5d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def augment(y):\n",
    "    noise = y + 0.005 * np.random.randn(len(y))\n",
    "    pitch = librosa.effects.pitch_shift(y, sr=SR, n_steps=2)\n",
    "    stretch = librosa.effects.time_stretch(y, rate=0.9)\n",
    "    return [noise, pitch, stretch]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a179c194",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f2591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y, genders = [], [], []\n",
    "\n",
    "for root, _, files in os.walk(DATASET_DIR):\n",
    "    for file in files:\n",
    "        if file.endswith(\".wav\"):\n",
    "            path = os.path.join(root, file)\n",
    "            emotion = file.split(\"-\")[2]\n",
    "            gender = \"male\" if int(file.split(\"-\")[6].split(\".\")[0]) % 2 else \"female\"\n",
    "\n",
    "            y_raw, y_trim = load_and_trim(path)\n",
    "            log_mel = extract_log_mel(y_trim)\n",
    "\n",
    "            if log_mel.shape[1] < MAX_LEN:\n",
    "                log_mel = np.pad(log_mel, ((0,0),(0,MAX_LEN-log_mel.shape[1])))\n",
    "            else:\n",
    "                log_mel = log_mel[:, :MAX_LEN]\n",
    "\n",
    "            X.append(log_mel[..., np.newaxis])\n",
    "            y.append(list(EMOTIONS.keys()).index(emotion))\n",
    "            genders.append(gender)\n",
    "\n",
    "            for aug in augment(y_trim):\n",
    "                mel_aug = extract_log_mel(aug)\n",
    "                mel_aug = mel_aug[:, :MAX_LEN]\n",
    "                X.append(mel_aug[..., np.newaxis])\n",
    "                y.append(list(EMOTIONS.keys()).index(emotion))\n",
    "                genders.append(gender)\n",
    "\n",
    "X = np.array(X)\n",
    "y = tf.keras.utils.to_categorical(y, 8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f600bf8c",
   "metadata": {},
   "source": [
    "## Train / Val / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26d5ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_temp, y_train, y_temp, g_train, g_temp = train_test_split(\n",
    "    X, y, genders, test_size=0.2, stratify=y.argmax(axis=1), random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test, g_val, g_test = train_test_split(\n",
    "    X_temp, y_temp, g_temp, test_size=0.5, stratify=y_temp.argmax(axis=1), random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fcc9a6",
   "metadata": {},
   "source": [
    "## CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67745564",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=X_train.shape[1:]),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ed2112",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d222af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5328b58c",
   "metadata": {},
   "source": [
    "## Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3caad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c908300d",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd82e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = model.predict(X_test).argmax(axis=1)\n",
    "y_true = y_test.argmax(axis=1)\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=EMOTIONS.values()))\n",
    "\n",
    "macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "print(\"Macro F1-score:\", macro_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480347de",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd7df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7810aade",
   "metadata": {},
   "source": [
    "## Gender Bias Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7192f509",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "male_idx = [i for i,g in enumerate(g_test) if g == \"male\"]\n",
    "female_idx = [i for i,g in enumerate(g_test) if g == \"female\"]\n",
    "\n",
    "male_acc = np.mean(y_pred[male_idx] == y_true[male_idx])\n",
    "female_acc = np.mean(y_pred[female_idx] == y_true[female_idx])\n",
    "\n",
    "print(\"Male Accuracy:\", male_acc)\n",
    "print(\"Female Accuracy:\", female_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d305479c",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa11529",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save(\"emotion_cnn.keras\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
